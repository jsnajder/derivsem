{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Polysemy in Derivational Models</h1>\n",
    "\n",
    "\n",
    "Version 13, 11 Feb 2016<br>\n",
    "Jan Å najder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from composes.matrix.dense_matrix import DenseMatrix\n",
    "from composes.matrix.sparse_matrix import SparseMatrix\n",
    "from composes.semantic_space.space import Space\n",
    "from composes.similarity.cos import CosSimilarity\n",
    "from composes.similarity.similarity import Similarity\n",
    "from composes.utils import io_utils\n",
    "from composes.transformation.scaling.row_normalization import RowNormalization\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Polysemy import *\n",
    "#from EvalPatterns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_path = \"/home/jan/b9-modality/\"\n",
    "data_path = \"/data/dsm/sdewac/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb-Adjective pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_file = proj_path + \"data/verb.adj.pairs\"\n",
    "pairs = sp.loadtxt(pairs_file, dtype=str)\n",
    "pairs = sp.array(map(lambda x : [x[0] + \"_V\", x[1] + \"_A\"], pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['offenbaren_V', 'offenbar_A'],\n",
       "       ['sichten_V', 'sichtbar_A'],\n",
       "       ['vergleichen_V', 'vergleichbar_A'],\n",
       "       ['scheinen_V', 'scheinbar_A'],\n",
       "       ['erkennen_V', 'erkennbar_A']], \n",
       "      dtype='|S18')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/data/dsm/sdewac/cbow/cbow_300dim_hs0/sdewac.300.cbow.hs0.vsm.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5222b88c8fa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspace_cbow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'cbow/cbow_300dim_hs0/sdewac.300.cbow.hs0.vsm.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mspace_cbow_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace_cbow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRowNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/dissect-0.1.0-py2.7.egg/composes/utils/io_utils.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(file_name, data_type)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/data/dsm/sdewac/cbow/cbow_300dim_hs0/sdewac.300.cbow.hs0.vsm.pkl'"
     ]
    }
   ],
   "source": [
    "space_cbow = io_utils.load(data_path + 'cbow/cbow_300dim_hs0/sdewac.300.cbow.hs0.vsm.pkl')\n",
    "space_cbow_norm = space_cbow.apply(RowNormalization(criterion = 'length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_cbow.cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(space_cbow.cooccurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isinstance(space_cbow.cooccurrence_matrix, DenseMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.shape(space_cbow.cooccurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v1 = space_cbow.get_row('Hund_N').mat\n",
    "v2 = space_cbow.get_row('Katze_N').mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space_ppmi = io_utils.load(data_path + 'count-based/sdewac_2015-11-23/sdewac-mst.prepro.bow-c10k-w5.ppmi.matrix.pkl')\n",
    "space_ppmi_norm = space_ppmi.apply(RowNormalization(criterion = 'length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_ppmi.cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(space_ppmi.cooccurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.shape(space_ppmi.cooccurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v3 = space_ppmi.get_row('Hund_N').mat\n",
    "v4 = space_ppmi.get_row('Katze_N').mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(v2.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v1 - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.shape(sp.transpose(v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.shape(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.dot(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v1.dot(v2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_cosine_distance(v1, v2):\n",
    "    if isinstance(v1, matrix) and isinstance(v2, matrix):\n",
    "        return cosine(v1, v2)\n",
    "    elif isinstance(v1, csr_matrix) and isinstance(v2, csr_matrix):\n",
    "        print 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v1.dot(v2.T)[0, 0] / (sp.linalg.norm(v1) * sp.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_dot(v1, v2): return v1.dot(v2.T)\n",
    "def my_norm(v): return sp.sqrt(my_dot(v, v)[0, 0])\n",
    "def my_cosine(v1, v2): return my_dot(v1, v2)[0, 0] / (my_norm(v1) * my_norm(v2))\n",
    "def my_cosine_dist(v1, v2): return 1 - my_cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_cosine(v3, v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(get_row_dense(space_cbow, 'Hund_N'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(get_row_dense(space_ppmi, 'Hund_N'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.linalg.norm(space_cbow.get_row('Hund_N').mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.linalg.norm(space_cbow_norm.get_row('Hund_N').mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_cbow.get_sim('Hund_N','Katze_N', CosSimilarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_cbow_norm.get_sim('Hund_N','Katze_N', CosSimilarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_cbow.get_sim('Hund_N','Kaufvertrag_N', CosSimilarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_cbow.get_sim('kaufen_V','Kaufvertrag_N', CosSimilarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_ppmi.get_sim('Hund_N','Katze_N', CosSimilarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_ppmi.get_sim('Hund_N','Kaufvertrag_N', CosSimilarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_ppmi.get_sim('kaufen_V','Kaufvertrag_N', CosSimilarity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gur350 check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gur350_gold= sp.genfromtxt(proj_path + \"data/gur350-gold.txt\", dtype=None, names=('w1', 'w2', 'gold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "predicted_cbow = space_cbow.get_sims(gur350_gold[['w1','w2']], CosSimilarity());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalCorrelation(predicted_cbow, gur350_gold['gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "predicted_ppmi = space_ppmi.get_sims(gur350_gold[['w1','w2']], CosSimilarity());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evalCorrelation(predicted_ppmi, gur350_gold['gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "for i, w in enumerate(['w2', 'w5', 'w10']):\n",
    "    space_cbow = io_utils.load(data_path + 'cbow/cbow_300dim_hs0/sdewac.300.cbow.hs0.' + w + '.vsm.pkl')\n",
    "    space_cbow_norm = space_cbow.apply(RowNormalization(criterion = 'length'))\n",
    "    predicted_cbow[i] = space_cbow.get_sims(gur350_gold[['w1','w2']], CosSimilarity());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, w in enumerate(['w2', 'w5', 'w10']):\n",
    "    print('%s: %s' % (w, evalCorrelation(predicted_cbow[i], gur350_gold['gold'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Model and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_kaufen = space_cbow.get_row('kaufen_V')\n",
    "get_neighbors(vector_kaufen, space_cbow, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_neighbors(vector_kaufen, space_cbow, n_neighbors=5, pos='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: comparison with Composes implementation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_cbow.get_neighbours('kaufen_V', 5, CosSimilarity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_cbow = BaselineModel(space_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score(baseline_cbow, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With POS restriction\n",
    "score(baseline_cbow, pairs, pos='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Additive model (prototype-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "additive_cbow = AdditiveModel(space_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score on the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "additive_cbow.fit(pairs)\n",
    "score(additive_cbow, pairs, pos='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score using 10-fold CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_cv(additive_cbow, pairs, random_state=42, pos='A', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score using LOOCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_cv(additive_cbow, pairs, random_state=42, pos='A', verbose=False, folds='loocv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Diff vectors clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, _ = get_diff_vectors(space_cbow, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "c = KMeans(n_clusters=2, random_state=42)\n",
    "c.fit(X)\n",
    "y1 = c.predict(X); y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_2d = PCA(n_components=2).fit_transform(X)\n",
    "scatter(X_2d[:,0], X_2d[:,1], c=c.predict(X), cmap='prism', s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from k_medoids import KMedoids\n",
    "c = KMedoids(n_clusters=2, random_state=42)\n",
    "c.fit(X)\n",
    "y1 = c.predict(X); y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_2d = PCA(n_components=2).fit_transform(X)\n",
    "scatter(X_2d[:,0], X_2d[:,1], c=c.predict(X), cmap='prism', s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from k_medoids import KMedoids\n",
    "c = KMedoids(n_clusters=2, random_state=42, distance_metric='cosine')\n",
    "c.fit(X)\n",
    "y1 = c.predict(X); y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_2d = PCA(n_components=2).fit_transform(X)\n",
    "scatter(X_2d[:,0], X_2d[:,1], c=c.predict(X), cmap='prism', s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, _ = make_classification(n_features=2, n_classes=2, n_informative=2, n_redundant=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from k_medoids import KMedoids\n",
    "c = KMedoids(n_clusters=2, random_state=42)\n",
    "c.fit(X)\n",
    "y1 = c.predict(X); y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "scatter(X[:,0], X[:,1], c=c.predict(X), cmap='prism', s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = get_base_vectors(space_cbow, pairs)\n",
    "shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "g = mixture.GMM(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.bic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "bic = []\n",
    "aic = []\n",
    "ks = range(1, 6)\n",
    "for k in ks:\n",
    "    g = mixture.GMM(n_components=k).fit(X) \n",
    "    bic.append(g.bic(X))\n",
    "    aic.append(g.aic(X))\n",
    "plt.plot(ks, aic, label=\"AIC\")\n",
    "plt.plot(ks, bic, label=\"BIC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = mixture.GMM(n_components=2)\n",
    "g.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_2d = PCA(n_components=2).fit_transform(X)\n",
    "scatter(X_2d[:,0], X_2d[:,1], c=g.predict(X), cmap='prism');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs1 = pairs[g.predict(X)==0]\n",
    "pairs2 = pairs[g.predict(X)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(pairs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(pairs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w1, w2 in pairs1:\n",
    "    print w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w1, w2 in pairs2:\n",
    "    print w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.savetxt(proj_path + \"data/dVA01-bar-cluster1.txt\", pairs1, fmt='%s')\n",
    "sp.savetxt(proj_path + \"data/dVA01-bar-cluster2.txt\", pairs2, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1 = AdditiveModel(space_cbow)\n",
    "model2 = AdditiveModel(space_cbow)\n",
    "model1.fit(pairs1)\n",
    "model2.fit(pairs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between the two diff vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "1 - cosine(model1.diff_vector.mat, model2.diff_vector.mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model scores on the train set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score(model1, pairs1, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score(model2, pairs2, pos='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV score, but optimistic, because test pairs always come from correct cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_cv(model1, pairs1, random_state=42, pos='A', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_cv(model2, pairs2, random_state=42, pos='A', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking differences between kmeans and gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sp.random.random((100,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = KMeans(n_clusters=2, random_state=42)\n",
    "c1.fit(X)\n",
    "y1 = c1.predict(X)\n",
    "c2 = mixture.GMM(n_components=2, covariance_type='tied', random_state=42)\n",
    "c2.fit(X)\n",
    "y2 = c2.predict(X)\n",
    "y1 == y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Generally, gmm and kmeans give different cluster assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster+predict model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering of diff vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = ClusterAdditiveModel(space_cbow, n_clusters=3, cluster_select='BasePredictSim', random_state=42)\n",
    "m.fit(pairs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = m.predict_with('kaufen_V', 0)\n",
    "get_neighbors(v, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = m.predict('kaufen_V', verbose=True)\n",
    "get_neighbors(v, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering of base words (rather than diff vectors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = ClusterAdditiveModel(space_cbow, n_clusters='BIC', clustering_instance='BaseWord', cluster_select='BasePredictSim', random_state=42)\n",
    "m.fit(pairs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = m.predict('kaufen_V', verbose=True)\n",
    "get_neighbors(v, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = ClusterAdditiveModel(space_cbow, n_clusters='BIC', clustering_instance='BaseWord', cluster_select='BaseClusterSim', random_state=42)\n",
    "m.fit(pairs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = m.predict('kaufen_V', verbose=True)\n",
    "get_neighbors(v, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.linalg.norm(v1.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_neighbors_sim(v1, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v2 = m.predict_with('kaufen_V', 1)\n",
    "get_neighbors(v2, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.linalg.norm(v2.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_neighbors_sim(v2, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Think again about vector normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.predict('kaufen_V', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = ClusterAdditiveModel(space_cbow, n_clusters=2, cluster_select='BasePredictSim', random_state=42)\n",
    "m.fit(pairs)\n",
    "score(m, pairs, verbose=False, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = ClusterAdditiveModel(space_ppmi, n_clusters=2, cluster_select='BasePredictSim', random_state=42)\n",
    "m.fit(pairs)\n",
    "score(m, pairs, verbose=False, pos='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_train, pairs_holdout = pairs[0:50,:], pairs[50:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shape(pairs_train), shape(pairs_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_kmeans = ClusterAdditiveModel(space_cbow, clustering='kmeans', n_clusters=2, cluster_select='BasePredictSim', random_state=42)\n",
    "score_cv(m_kmeans, pairs_train, pos='A', random_state=42, test_pairs_extra=pairs_holdout, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_kmeans = ClusterAdditiveModel(space_cbow, clustering='kmeans', n_clusters=2, cluster_select='BasePredictSim', random_state=42)\n",
    "score_cv(m_kmeans, pairs, pos='A', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_kmeans = ClusterAdditiveModel(space_cbow, clustering='kmedoids', n_clusters=2, cluster_select='BasePredictSim', random_state=42)\n",
    "score_cv(m_kmeans, pairs, pos='A', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_kmeans = ClusterAdditiveModel(space_cbow, clustering='kmeans', n_clusters=2, cluster_select='BaseSim', random_state=66)\n",
    "score_cv(m_kmeans, pairs, pos='A', random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_gmm = ClusterAdditiveModel(space_cbow, clustering='gmm', n_clusters=2, cluster_select='BaseSim', random_state=42)\n",
    "score_cv(m_gmm, pairs, pos='A', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_gmm = ClusterAdditiveModel(space_cbow, clustering='gmm', n_clusters=2, cluster_select='BaseSim', random_state=42)\n",
    "score_cv(m_gmm, pairs, pos='A', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_gmm = ClusterAdditiveModel(space_cbow, clustering='gmm', n_clusters=2, cluster_select='BaseSim', random_state=66)\n",
    "score_cv(m_gmm, pairs, pos='A', random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing kmeans and gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_gmm = ClusterAdditiveModel(space_cbow, clustering='gmm', n_clusters=2, cluster_select='BaseSim', random_state=42)\n",
    "m_gmm.fit(pairs)\n",
    "y1 = m_gmm.cluster_assignments\n",
    "\n",
    "m_kmeans = ClusterAdditiveModel(space_cbow, clustering='kmeans', n_clusters=2, cluster_select='BaseSim', random_state=42)\n",
    "m_kmeans.fit(pairs)\n",
    "y2 = m_kmeans.cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y1 == y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> In our case, cluster assignments are equivalent for kmeans and gmm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplar model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = AdditiveExemplarModel(space_cbow)\n",
    "m.fit(pairs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = m.predict('kaufen_V', verbose=True)\n",
    "get_neighbors(v, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = m.predict('singen_V', verbose=True)\n",
    "get_neighbors(v, space_cbow, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = AdditiveExemplarModel(space_ppmi)\n",
    "m.fit(pairs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = m.predict('kaufen_V', verbose=True)\n",
    "get_neighbors(v, space_ppmi, pos='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Filtering based on GermanWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reads in pairs with polysemy level as the first attribute\n",
    "def load_pairs(filename, pos1, pos2):\n",
    "    lines = sp.loadtxt(filename, dtype=str)\n",
    "    return map(lambda x : [int(x[0]), x[1] + \"_V\", x[2] + \"_A\"], lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dVA01 = load_pairs(proj_path + \"data/dVA01-bar-data.polysemy\", 'V', 'A')\n",
    "dVA01_pairs = sp.array(dVA01)[:,[1,2]]\n",
    "dVA01_monosemous_pairs = sp.array([(w1,w2) for (p, w1, w2) in dVA01 if p<=1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dVA01_monosemous_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dVA01_monosemous_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_cbow = BaselineModel(space_cbow)\n",
    "score_cv(baseline_cbow, dVA01_monosemous_pairs, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "additive_cbow = AdditiveModel(space_cbow)\n",
    "additive_cbow.fit(dVA01_monosemous_pairs)\n",
    "score_cv(additive_cbow, dVA01_monosemous_pairs, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_additive_cbow = ClusterAdditiveModel(space_cbow, n_clusters='BIC', cluster_select='BaseSim', random_state=42)\n",
    "cluster_additive_cbow.fit(dVA01_monosemous_pairs, verbose=True)\n",
    "score_cv(cluster_additive_cbow, dVA01_monosemous_pairs, random_state=42, pos='A', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(3, 7):\n",
    "    print('\\nk=%d' % k)\n",
    "    cluster_additive_cbow = ClusterAdditiveModel(space_cbow, n_clusters=k, cluster_select='BaseSim', random_state=42)\n",
    "    cluster_additive_cbow.fit(dVA01_monosemous_pairs, verbose=True)\n",
    "    print score_cv(cluster_additive_cbow, dVA01_monosemous_pairs, random_state=42, pos='A', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering based on InvCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reads in pairs with inclusion data (invCL)\n",
    "# File format is:\n",
    "#   offenbar_A offenbaren_V clarkeDE: 0.134455726236 invCL: 0.328609106994\n",
    "def load_pairs(filename):\n",
    "    lines = sp.loadtxt(filename, dtype=str)\n",
    "    return map(lambda x : [float(x[5]), x[1], x[0]], lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dVA01 = load_pairs(proj_path + \"data/dVA01-bar-data.inclusion\")\n",
    "dVA01_pairs = sp.array(dVA01)[:,[1,2]]\n",
    "dVA01_inclusive_pairs = sp.array([(w1,w2) for (i, w1, w2) in dVA01 if i>=0.72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dVA01_inclusive_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_cbow = BaselineModel(space_cbow)\n",
    "score_cv(baseline_cbow, dVA01_inclusive_pairs, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "additive_cbow = AdditiveModel(space_cbow)\n",
    "additive_cbow.fit(dVA01_inclusive_pairs)\n",
    "score_cv(additive_cbow, dVA01_inclusive_pairs, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_additive_cbow = ClusterAdditiveModel(space_cbow, n_clusters='BIC', cluster_select='BaseSim', random_state=42)\n",
    "cluster_additive_cbow.fit(dVA01_inclusive_pairs, verbose=True)\n",
    "score_cv(cluster_additive_cbow, dVA01_inclusive_pairs, random_state=42, pos='A', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(3, 7):\n",
    "    print('k=%d' % k)\n",
    "    cluster_additive_cbow = ClusterAdditiveModel(space_cbow, n_clusters=k, cluster_select='BaseSim', random_state=42)\n",
    "    cluster_additive_cbow.fit(dVA01_inclusive_pairs, verbose=True)\n",
    "    print score_cv(cluster_additive_cbow, dVA01_inclusive_pairs, random_state=42, pos='A', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering based on Polysemy + InvCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.intersect1d(dVA01_monosemous_pairs, dVA01_inclusive_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_df = pd.read_csv(proj_path + \"data/pairs.txt\", sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dVA01_wellbehaved_df = pairs_df[conjunction(pairs_df.pattern=='dVA01', pairs_df.polysemy<=1, pairs_df.invCL>=0.5)]\n",
    "dVA01_wellbehaved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dVA01_wellbehaved_pairs = sp.array(pairs_wellbehaved_df[['word1', 'word2']])\n",
    "dVA01_wellbehaved_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_cbow = BaselineModel(space_cbow)\n",
    "score_cv(baseline_cbow, dVA01_wellbehaved_pairs, pos='A', folds=len(dVA01_wellbehaved_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "additive_cbow = AdditiveModel(space_cbow)\n",
    "additive_cbow.fit(dVA01_wellbehaved_pairs)\n",
    "score_cv(additive_cbow, dVA01_wellbehaved_pairs, pos='A', folds=len(dVA01_wellbehaved_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_additive_cbow = ClusterAdditiveModel(space_cbow, n_clusters='BIC', cluster_select='BaseSim', random_state=42)\n",
    "cluster_additive_cbow.fit(dVA01_wellbehaved_pairs, verbose=True)\n",
    "score_cv(cluster_additive_cbow, dVA01_wellbehaved_pairs, random_state=42, pos='A', verbose=False, folds=len(dVA01_wellbehaved_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(3, 7):\n",
    "    print('k=%d' % k)\n",
    "    cluster_additive_cbow = ClusterAdditiveModel(space_cbow, n_clusters=k, cluster_select='BaseSim', random_state=42)\n",
    "    cluster_additive_cbow.fit(dVA01_wellbehaved_pairs, verbose=True)\n",
    "    print score_cv(cluster_additive_cbow, dVA01_wellbehaved_pairs, random_state=42, pos='A', verbose=False, folds=len(dVA01_wellbehaved_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Grand experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_df = pd.read_csv(proj_path + \"data/all/pairs-all.txt\", sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pattern_pos(pattern): return (pattern[1], pattern[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern_pos('dVV31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_invCL(pairs_df, pattern):\n",
    "    return pairs_df[pairs_df.pattern == pattern]['invCL'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_invCL(pairs_df, 'dAA02') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For a given pattern, fetches rows from a dataframe that satisfy the given poysemy and invCL thresholds.\n",
    "# Returns two dataframes: one containing rows that satisfy the conditions and one containing those that don't.\n",
    "def partition_pairs(pairs_df, pattern, polysemy_threshold=None, invCL_threshold=None, only_pairs=False):\n",
    "    \n",
    "    def get_pairs(df): return sp.array(df[['word1','word2']])\n",
    "    \n",
    "    ix0 = sp.logical_and(pairs_df.polysemy <= polysemy_threshold if polysemy_threshold != None else True,\n",
    "                         pairs_df.invCL >= invCL_threshold if invCL_threshold != None else True)\n",
    "    ix1 = sp.logical_and(pairs_df.pattern == pattern, ix0)\n",
    "    ix2 = sp.logical_and(pairs_df.pattern == pattern, ~ix0)\n",
    "    \n",
    "    if only_pairs:\n",
    "        return get_pairs(pairs_df[ix1]), get_pairs(pairs_df[ix2])\n",
    "    else:\n",
    "        return pairs_df[ix1], pairs_df[ix2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1, df2 = partition_pairs(pairs_df, 'dAA02', polysemy_threshold=1, invCL_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_pattern(space, pairs_df, pattern, folds=10, random_state=None, verbose=False):\n",
    "\n",
    "    models = [\n",
    "        ('Baseline', BaselineModel(space)), \n",
    "        ('Additive', AdditiveModel(space)),\n",
    "        ('AdditiveExemplar', AdditiveExemplarModel(space))] + \\\n",
    "        [('CluAdditive (DiffVectors, kmeans, k=%d, BasePredictSim)' % k, \n",
    "         ClusterAdditiveModel(space, clustering_instance='DiffVector', clustering='kmeans', n_clusters=k, cluster_select='BasePredictSim', random_state=random_state)) \n",
    "         for k in range(2,6)] + \\\n",
    "        [('CluAdditive (BaseWord, kmeans, k=%d, BasePredictSim)' % k, \n",
    "         ClusterAdditiveModel(space, clustering_instance='BaseWord', clustering='kmeans', n_clusters=k, cluster_select='BasePredictSim', random_state=random_state)) \n",
    "         for k in range(2,6)] + \\\n",
    "        [('CluAdditive (BaseWord, kmeans, k=%d, BaseClusterSim)' % k, \n",
    "         ClusterAdditiveModel(space, clustering_instance='BaseWord', clustering='kmeans', n_clusters=k, cluster_select='BaseClusterSim', random_state=random_state)) \n",
    "         for k in range(2,6)]\n",
    "            \n",
    "    pairs_all, _ = partition_pairs(pairs_df, pattern, only_pairs=True)\n",
    "    pairs_mono1, pairs_mono0 = partition_pairs(pairs_df, pattern, polysemy_threshold=1, only_pairs=True)\n",
    "    pairs_incl1, pairs_incl0 = partition_pairs(pairs_df, pattern, invCL_threshold=0.5, only_pairs=True)\n",
    "    pairs_monoincl1, pairs_monoincl0 = partition_pairs(pairs_df, pattern, polysemy_threshold=1, invCL_threshold=0.5, only_pairs=True)\n",
    "\n",
    "    _, deriv_pos = pattern_pos(pattern)\n",
    "\n",
    "    data = [\n",
    "        ('All', pairs_all, None),\n",
    "        ('Mono', pairs_mono1, None),\n",
    "        ('Incl', pairs_incl1, None),\n",
    "        ('MonoIncl', pairs_monoincl1, None),\n",
    "        ('Mono', pairs_mono1, pairs_mono0),\n",
    "        ('Incl', pairs_incl1, pairs_incl0),\n",
    "        ('MonoIncl', pairs_monoincl1, pairs_monoincl0)]\n",
    "\n",
    "    model_names = [n for n, _ in models]\n",
    "    data_names = ['%s (%s:%d+%d)' % (pattern, pairs_name, len(pairs_train), \n",
    "                                     len(pairs_extra_test) if pairs_extra_test != None else 0)\n",
    "                  for pairs_name, pairs_train, pairs_extra_test in data]\n",
    "    scores_df = pd.DataFrame(index=model_names, columns=data_names)\n",
    "    \n",
    "    for data_name, (_, pairs_train, pairs_extra_test) in zip(data_names, data):\n",
    "        if verbose:\n",
    "            print('Data: %s' % data_name)\n",
    "        for model_name, model in models:\n",
    "            _, rof, rof_error = score_cv(model, pairs_train, test_pairs_extra=pairs_extra_test,\n",
    "                                         pos=deriv_pos, folds=folds, random_state=random_state)\n",
    "            scores_df[data_name][model_name] = '%.3f Â± %.2f' % (rof, rof_error)\n",
    "            if verbose:\n",
    "                print('  %s: %.3f Â± %.2f' % (model_name, rof, rof_error))\n",
    "    \n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = eval_pattern(space_cbow, pairs_df, 'dAA02', folds=10, random_state=42); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.unique(pairs_df['pattern'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patterns = pd.unique(pairs_df['pattern'])\n",
    "writer = pd.ExcelWriter('PolysemyDerivation-cbow-norm.xlsx')\n",
    "\n",
    "for pattern in patterns:\n",
    "    df = eval_pattern(space_cbow_norm, pairs_df, pattern, folds=10, random_state=42, verbose=True)\n",
    "    df.to_excel(writer, pattern)\n",
    "    writer.save()\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patterns = pd.unique(pairs_df['pattern'])\n",
    "writer = pd.ExcelWriter('PolysemyDerivation-ppmi.xlsx')\n",
    "\n",
    "for pattern in patterns:\n",
    "    df = eval_pattern(space_ppmi, pairs_df, pattern, folds=10, random_state=42)\n",
    "    df.to_excel(writer, pattern)\n",
    "    writer.save()\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median_invCL(pairs_df, pattern):\n",
    "    return pairs_df[pairs_df.pattern == pattern]['invCL'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pattern_pos(pattern): return (pattern[1], pattern[2])\n",
    "\n",
    "# For a given pattern, fetches rows from a dataframe that satisfy the given poysemy and invCL thresholds.\n",
    "# Returns two dataframes: one containing rows that satisfy the conditions and one containing those that don't.\n",
    "def partition_pairs(pairs_df, pattern, polysemy_threshold=None, invCL_threshold=None, only_pairs=False):\n",
    "\n",
    "    def get_pairs(df): return sp.array(df[['word1','word2']])\n",
    "\n",
    "    ix0 = sp.logical_and(pairs_df.polysemy <= polysemy_threshold if polysemy_threshold != None else True,\n",
    "                         pairs_df.invCL >= invCL_threshold if invCL_threshold != None else True)\n",
    "    ix1 = sp.logical_and(pairs_df.pattern == pattern, ix0)\n",
    "    ix2 = sp.logical_and(pairs_df.pattern == pattern, ~ix0)\n",
    "\n",
    "    if only_pairs:\n",
    "        return get_pairs(pairs_df[ix1]), get_pairs(pairs_df[ix2])\n",
    "    else:\n",
    "        return pairs_df[ix1], pairs_df[ix2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: dAV01 (MonoIncl:46+59)\n",
    " CluAdditive (BaseWord, kmeans, k=3, BaseClusterSim): 0.495 Â± 0.12\n",
    " /proj/sci/b9/modality/ipython/k_medoids.py:176: UserWarning: Cluster 2 is empty!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: dAV04 (All:185+0)\n",
    "CluAdditive (BaseWord, kmedoids, k=2, BasePredictSim): 0.351 Â± 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_df = pd.read_csv('/home/jan/b9-modality/data/pairs-XX/pairs-AV.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = 'dAV04'\n",
    "folds = 10\n",
    "\n",
    "invCL_median = median_invCL(pairs_df, pattern)\n",
    "\n",
    "pairs_all, _ = partition_pairs(pairs_df, pattern, only_pairs=True)\n",
    "pairs_mono1, pairs_mono0 = partition_pairs(pairs_df, pattern, polysemy_threshold=1, only_pairs=True)\n",
    "pairs_incl1, pairs_incl0 = partition_pairs(pairs_df, pattern, invCL_threshold=invCL_median, only_pairs=True)\n",
    "pairs_monoincl1, pairs_monoincl0 = partition_pairs(pairs_df, pattern, polysemy_threshold=1, invCL_threshold=invCL_median, only_pairs=True)\n",
    "pairs_train = pairs_all\n",
    "pairs_extra_test = None\n",
    "\n",
    "_, deriv_pos = pattern_pos(pattern)\n",
    "\n",
    "model = ClusterAdditiveModel(space_cbow_norm, clustering_instance='BaseWord', clustering='kmedoids', n_clusters=3, cluster_select='BasePredictSim', random_state=42)\n",
    "\n",
    "_, rof, rof_error = score_cv(model, pairs_train, test_pairs_extra=pairs_extra_test, pos=deriv_pos, folds=folds, random_state=42)\n",
    "print('%.3f Â± %.2f' % (rof, rof_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = [9, 18, 29, 30, 55, 56,  60,  65,  66,  75, 113, 119, 124, 126, 135, 146, 165, 170, 176]\n",
    "train_ix = sp.delete(sp.arange(0,185), test_ix)\n",
    "train_pairs = pairs_train[train_ix]\n",
    "test_pairs = pairs_train[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_pairs), len(test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = get_base_vectors(space_cbow_norm, train_pairs)\n",
    "Y = get_base_vectors(space_cbow_norm, test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = get_base_vectors(self.space, train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = KMedoids(n_clusters=3, random_state=42, distance_metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = space_cbow_norm.get_row('Hund_N') + DenseMatrix(sp.zeros(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v.mat == space_cbow_norm.get_row('Hund_N').mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "space_cbow_norm.get_row('Hund_N').mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_pattern(space_cbow, pairs_df, 'dAV04', random_state=42, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: dAV04 (All:185+0)\n",
    "  Baseline: 0.362 Â± 0.06\n",
    "  Additive: 0.367 Â± 0.07\n",
    "  AdditiveExemplar: 0.167 Â± 0.05\n",
    "  CluAdditive (DiffVectors, kmeans, k=2, BasePredictSim): 0.340 Â± 0.05\n",
    "  CluAdditive (DiffVectors, kmeans, k=3, BasePredictSim): 0.367 Â± 0.07\n",
    "  CluAdditive (DiffVectors, kmeans, k=4, BasePredictSim): 0.345 Â± 0.05\n",
    "  CluAdditive (DiffVectors, kmeans, k=5, BasePredictSim): 0.351 Â± 0.06\n",
    "  CluAdditive (DiffVectors, kmedoids, k=2, BasePredictSim): 0.351 Â± 0.07\n",
    "  CluAdditive (DiffVectors, kmedoids, k=3, BasePredictSim): 0.346 Â± 0.06\n",
    "  CluAdditive (DiffVectors, kmedoids, k=4, BasePredictSim): 0.345 Â± 0.06\n",
    "  CluAdditive (DiffVectors, kmedoids, k=5, BasePredictSim): 0.323 Â± 0.07\n",
    "  CluAdditive (BaseWord, kmeans, k=2, BasePredictSim): 0.356 Â± 0.06\n",
    "  CluAdditive (BaseWord, kmeans, k=3, BasePredictSim): 0.356 Â± 0.07\n",
    "  CluAdditive (BaseWord, kmeans, k=4, BasePredictSim): 0.361 Â± 0.08\n",
    "  CluAdditive (BaseWord, kmeans, k=5, BasePredictSim): 0.351 Â± 0.06\n",
    "  CluAdditive (BaseWord, kmedoids, k=2, BasePredictSim): 0.351 Â± 0.06\n",
    "Traceback (most recent call last):\n",
    "  File \"EvalPatterns.py\", line 122, in <module>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooled results (2x2 design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = ClusterAdditiveModel(space_cbow_norm, clustering_instance='BaseWord', clustering='kmedoids', n_clusters='AIC', cluster_select='BaseClusterSim', random_state=42)\n",
    "m.fit(pairs, verbose=True)\n",
    "#score(m, pairs, verbose=False, pos='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, rof, rof_error = score_cv(model, pairs_train, test_pairs_extra=pairs_extra_test,\n",
    "                                         pos=deriv_pos, folds=folds, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_df = pd.read_csv(proj_path + \"data/all/pairs-all.txt\", sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = eval_pattern_2(space_cbow_norm, pairs_df, 'dAA03', random_state=42, verbose=True); r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "path = proj_path + 'ipython/results2/'\n",
    "xs = os.listdir(path)\n",
    "d = pd.read_excel(path + xs[0])\n",
    "for x in xs[1:]:\n",
    "    d2 = pd.read_excel(path + x)\n",
    "    d = d.add(d2)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d / d['All']['n_pairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zs = ['dAN03', 'dAN04', 'dAN09', 'dAN10', 'dAN11', 'dAN12', 'dAN16', 'dNA01', 'dNA02', 'dNA05', 'dNA06', 'dNA25', 'dNA26', 'dNA27', 'dNV09', 'dVA02', 'dVA03', 'dVA12', 'dVA13', 'dVN07', 'dVN09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ws = [x for x in xs if not any([z in x for z in zs])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "d = pd.read_excel(path + ws[0])\n",
    "for w in ws[1:]:\n",
    "    d2 = pd.read_excel(path + w)\n",
    "    d = d.add(d2)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d / d['All']['n_pairs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO (24 Jan 2016)\n",
    "\n",
    "* <strike>Fix score_cv</strike>\n",
    "* <strike>Implement POS filter in the scoring functions</strike>\n",
    "* <strike>invCL filtering</strike>\n",
    "* <strike>Put all word pairs data into a single Pandas dataframe</strike>\n",
    "* <strike>Check clustering variance</strike>\n",
    "* Implement oracles\n",
    "* <strike>Stability of GMM (initial centroids)</strike>\n",
    "* <strike>GMM parameters (maybe use full cov matrix?)</strike>\n",
    "* <strike>Implement k-nn instead of GMM</strike>\n",
    "* <strike>All patterns</strike>\n",
    "* <strike>Train on subset, predict on all</strike>\n",
    "* <strike>Exemplar model</strike>\n",
    "* <strike>Base-centroid cluster selection</strike>\n",
    "* <strike>**Grand experiment**</strike>\n",
    "* <strike>Cluter base word</strike>\n",
    "* <strike>Check gmm vs kmeans results</strike>\n",
    "* <strike>Fix margin of error for LOOCV</strike>\n",
    "* Evaluate with a count-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector plausibility\n",
    "\n",
    "* Vecchi et al 2011. (http://aclweb.org/anthology/W/W11/W11-1301.pdf)\n",
    "\n",
    "\n",
    "1. Vector length\n",
    "\n",
    "2. Similarity to base verb vector\n",
    "\n",
    "3. Avg/median similarity to N nearest neighbors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Oracles\n",
    "\n",
    "* n_clusters:\n",
    "  * the number of clusters that maximizes RooN\n",
    "\n",
    "* cluster_select:\n",
    "  * choose the cluster that maximizes RooN (if there is such)\n",
    "  * compute the gold diff vector and choose the cluster which maximizes the class likelihood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
